{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.layers as tfl\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# with zipfile.ZipFile(\"archive (4).zip\", \"r\") as file:\n",
    "#     file.extractall(\"EmojiDataset\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "glove_embeddings = {}\n",
    "\n",
    "with open(\"glove.6B.100d.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        glove_embeddings[word] = np.array(values[1:], dtype=\"float32\")\n",
    "\n",
    "print(len(glove_embeddings))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def get_y(csv_filename):\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    y = tf.one_hot(df.iloc[:, -1].values, depth = 20)\n",
    "    return y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def get_avg_embedding(sentence):\n",
    "    words = np.array(sentence.split())\n",
    "    words_embeddings = np.array([glove_embeddings[x.lower()] if (x.lower() in glove_embeddings.keys()) else np.zeros((100,)) for x in words])\n",
    "    return np.mean(words_embeddings)\n",
    "\n",
    "def get_x_naive(csv_filename):\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    x = df.iloc[:, -2].values\n",
    "    x = np.vectorize(lambda sentence: get_avg_embedding(sentence))(x)\n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "array([-0.00423002, -0.00381428, -0.02088024, -0.00710395, -0.01055331])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_naive_df = get_x_naive(\"EmojiDataset/train.csv\")\n",
    "x_train_naive_df[:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(5, 20), dtype=float32, numpy=\narray([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.]], dtype=float32)>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_df = get_y(\"EmojiDataset/train.csv\")\n",
    "y_train_df[:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "naive_model = tf.keras.models.Sequential([\n",
    "    tfl.Dense(256, activation=\"relu\", input_shape=(1,)),\n",
    "    tfl.Dense(20, activation=\"softmax\")\n",
    "])\n",
    "naive_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2188/2188 [==============================] - 4s 2ms/step - loss: 2.7421 - accuracy: 0.2154\n",
      "Epoch 2/5\n",
      "2188/2188 [==============================] - 3s 2ms/step - loss: 2.7337 - accuracy: 0.2156\n",
      "Epoch 3/5\n",
      "2188/2188 [==============================] - 3s 2ms/step - loss: 2.7323 - accuracy: 0.2156\n",
      "Epoch 4/5\n",
      "2188/2188 [==============================] - 4s 2ms/step - loss: 2.7318 - accuracy: 0.2156\n",
      "Epoch 5/5\n",
      "2188/2188 [==============================] - 4s 2ms/step - loss: 2.7314 - accuracy: 0.2156\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x1ae2ddc4450>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_model.fit(x_train_naive_df, y_train_df, epochs=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Naive model does not get high accuracy, but given that random guessing would yield around 5% this is still pretty good.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## LSTM Model\n",
    "Implementing an adaptation of the LSTM model described in [this github repository](https://github.com/amanchadha/coursera-deep-learning-specialization/blob/master/C5%20-%20Sequence%20Models/Week%202/Emojify/Emoji_v3a.ipynb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "from keras.src.utils import pad_sequences\n",
    "\n",
    "\n",
    "def get_x_embed(sentence, maxlen):\n",
    "    word_arr = np.array(sentence.split())\n",
    "    if len(word_arr) < maxlen:\n",
    "        padding = maxlen - len(word_arr)\n",
    "        word_arr = np.pad(word_arr, (0, padding), mode=\"constant\", constant_values=\"<OOVo>\")\n",
    "    if len(word_arr) > maxlen:\n",
    "        word_arr = word_arr[:maxlen]\n",
    "    sentence_embeddings = np.array([glove_embeddings[x.lower()] if (x.lower() in glove_embeddings.keys()) else np.zeros((100,)) for x in word_arr])\n",
    "\n",
    "    return sentence_embeddings\n",
    "\n",
    "def get_x(csv_filename, maxlen=50):\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    sentences_arr = df[\"TEXT\"].values\n",
    "    embeddings = np.array([get_x_embed(x, maxlen) for x in sentences_arr])\n",
    "    return embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method NDFrame.head of 0        Vacation wasted ! #vacation2017 #photobomb #ti...\n1        Oh Wynwood, youâ€™re so funny! : @user #Wynwood ...\n2        Been friends since 7th grade. Look at us now w...\n3        This is what it looks like when someone loves ...\n4        RT @user this white family was invited to a Bl...\n                               ...                        \n69995    Yes, I call Galina \"my Bubie\" Go follow my bea...\n69996      I SEA you, Seattle @ Ballard Seafood Festival\\n\n69997    If one of my daughters is wearing this and ask...\n69998    Guess who whoop people on THEIR homecoming?! #...\n69999    We Love you Robbie @ Heritage Memorial Cemeter...\nName: TEXT, Length: 70000, dtype: object>"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_alpha = pd.read_csv(\"EmojiDataset/train.csv\")\n",
    "test_alpha.iloc[:, -2].head"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 50, 100) (25958, 50, 100)\n"
     ]
    }
   ],
   "source": [
    "x_train = get_x(\"EmojiDataset/train.csv\")\n",
    "x_test = get_x(\"EmojiDataset/test.csv\")\n",
    "print(x_train.shape, x_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
