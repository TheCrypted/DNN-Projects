{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n"
     ]
    }
   ],
   "source": [
    "train_size = os.listdir(\"Dataset/train/images\")\n",
    "print(len(train_size))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "training_model = YOLO(\"yolov8n.yaml\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# train_images = os.listdir(\"Dataset/train/images\")\n",
    "# train_labels = os.listdir(\"Dataset/train/labels\")\n",
    "# REDUCED_SIZE = 15000\n",
    "#\n",
    "# print(len(os.listdir(\"Dataset/train/images\")))\n",
    "# for image, label in zip(train_images[REDUCED_SIZE:], train_labels[REDUCED_SIZE:]):\n",
    "#     os.remove(os.path.join(\"Dataset/train/labels\", label))\n",
    "#     os.remove(os.path.join(\"Dataset/train/images\", image))\n",
    "# # print(os.listdir(\"Dataset/train/labels\"))\n",
    "# print(len(os.listdir(\"Dataset/train/labels\")))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.172 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.159  Python-3.11.0 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0mtask=detect, mode=train, model=yolov8n.yaml, data=Dataset/data.yaml, epochs=50, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train\n",
      "Overriding model.yaml nc=80 with nc=52\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    761452  ultralytics.nn.modules.head.Detect           [52, [64, 128, 256]]          \n",
      "YOLOv8n summary: 225 layers, 3020988 parameters, 3020972 gradients\n",
      "\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs\\detect\\train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed \n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\Aman's Laptop\\Documents\\DNNProjects\\PokerHandDetection\\Dataset\\train\\labels.cache... 15000 images, 0 backgrounds, 0 corrupt: 100%|██████████| 15000/15000 [00:00<?, ?it/s]\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\Aman's Laptop\\Documents\\DNNProjects\\PokerHandDetection\\Dataset\\valid\\labels.cache... 2020 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2020/2020 [00:00<?, ?it/s]\n",
      "Plotting labels to runs\\detect\\train\\labels.jpg... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001B[1mruns\\detect\\train\u001B[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/50      2.53G      3.225       5.39      2.606         37        640: 100%|██████████| 938/938 [02:06<00:00,  7.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:16<00:00,  3.89it/s]\n",
      "                   all       2020       8080     0.0111      0.806     0.0185    0.00944\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/50      2.56G      1.645      3.381      1.339         38        640: 100%|██████████| 938/938 [02:09<00:00,  7.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:18<00:00,  3.46it/s]\n",
      "                   all       2020       8080      0.108      0.395      0.121     0.0659\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/50      2.57G      1.481      2.664      1.221         44        640: 100%|██████████| 938/938 [02:14<00:00,  6.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:18<00:00,  3.43it/s]\n",
      "                   all       2020       8080      0.317      0.641      0.403      0.278\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/50      2.56G      1.423      2.043      1.179         50        640: 100%|██████████| 938/938 [02:16<00:00,  6.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:16<00:00,  3.77it/s]\n",
      "                   all       2020       8080      0.661      0.824        0.8      0.497\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/50      2.56G      1.378        1.5      1.155         53        640: 100%|██████████| 938/938 [02:16<00:00,  6.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:16<00:00,  3.86it/s]\n",
      "                   all       2020       8080      0.896      0.925      0.969      0.628\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/50      2.55G      1.349      1.195      1.139         35        640: 100%|██████████| 938/938 [02:21<00:00,  6.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:17<00:00,  3.60it/s]\n",
      "                   all       2020       8080       0.96      0.968      0.991       0.68\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/50      2.55G      1.333      1.035      1.132         43        640: 100%|██████████| 938/938 [02:17<00:00,  6.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:16<00:00,  3.79it/s]\n",
      "                   all       2020       8080      0.982      0.985      0.994      0.667\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/50      2.55G      1.322     0.9406      1.124         47        640: 100%|██████████| 938/938 [02:22<00:00,  6.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:17<00:00,  3.73it/s]\n",
      "                   all       2020       8080      0.988      0.992      0.995      0.658\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/50      2.55G       1.31     0.8732      1.119         49        640: 100%|██████████| 938/938 [02:16<00:00,  6.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:17<00:00,  3.72it/s]\n",
      "                   all       2020       8080      0.993      0.996      0.995      0.662\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/50      2.55G      1.302     0.8205      1.114         45        640: 100%|██████████| 938/938 [02:10<00:00,  7.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:15<00:00,  4.12it/s]\n",
      "                   all       2020       8080      0.996      0.998      0.995      0.655\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/50      2.55G      1.294     0.7829      1.107         23        640: 100%|██████████| 938/938 [02:07<00:00,  7.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:16<00:00,  3.89it/s]\n",
      "                   all       2020       8080      0.997      0.996      0.995      0.689\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/50      2.55G      1.284     0.7529      1.103         29        640: 100%|██████████| 938/938 [02:08<00:00,  7.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:15<00:00,  4.10it/s]\n",
      "                   all       2020       8080      0.993      0.996      0.995      0.651\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/50      2.55G       1.28     0.7369      1.099         52        640: 100%|██████████| 938/938 [02:07<00:00,  7.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:16<00:00,  3.96it/s]\n",
      "                   all       2020       8080      0.996      0.998      0.995      0.672\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/50      2.55G      1.276      0.716      1.096         57        640: 100%|██████████| 938/938 [02:08<00:00,  7.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:15<00:00,  4.05it/s]\n",
      "                   all       2020       8080      0.997      0.999      0.995      0.686\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/50      2.55G      1.271     0.6977      1.096         35        640: 100%|██████████| 938/938 [02:06<00:00,  7.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:15<00:00,  4.06it/s]\n",
      "                   all       2020       8080      0.997      0.999      0.995      0.679\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/50      2.54G      1.264     0.6852      1.089         47        640: 100%|██████████| 938/938 [02:08<00:00,  7.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:16<00:00,  3.84it/s]\n",
      "                   all       2020       8080      0.998      0.999      0.995      0.682\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/50      2.55G      1.267     0.6731      1.088         65        640: 100%|██████████| 938/938 [02:11<00:00,  7.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:16<00:00,  3.78it/s]\n",
      "                   all       2020       8080      0.998      0.999      0.995      0.672\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/50      2.54G      1.256     0.6594      1.086         40        640: 100%|██████████| 938/938 [02:10<00:00,  7.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:15<00:00,  4.03it/s]\n",
      "                   all       2020       8080      0.999      0.999      0.995      0.686\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/50      2.55G       1.25     0.6532      1.082         51        640: 100%|██████████| 938/938 [02:11<00:00,  7.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:16<00:00,  3.98it/s]\n",
      "                   all       2020       8080      0.998          1      0.995      0.683\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/50      2.55G      1.249     0.6456      1.081         55        640: 100%|██████████| 938/938 [02:10<00:00,  7.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:15<00:00,  4.03it/s]\n",
      "                   all       2020       8080      0.999      0.999      0.995      0.673\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      21/50      2.55G      1.246     0.6323      1.083         26        640: 100%|██████████| 938/938 [02:11<00:00,  7.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:16<00:00,  3.97it/s]\n",
      "                   all       2020       8080      0.999      0.999      0.995      0.695\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      22/50      2.55G      1.244     0.6273      1.079         43        640: 100%|██████████| 938/938 [02:09<00:00,  7.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:15<00:00,  4.03it/s]\n",
      "                   all       2020       8080      0.999      0.999      0.995      0.696\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      23/50      2.55G       1.24     0.6164      1.077         38        640: 100%|██████████| 938/938 [02:10<00:00,  7.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:15<00:00,  4.13it/s]\n",
      "                   all       2020       8080      0.999      0.999      0.995      0.697\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      24/50      2.54G      1.238     0.6126      1.075         63        640: 100%|██████████| 938/938 [02:06<00:00,  7.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:15<00:00,  4.09it/s]\n",
      "                   all       2020       8080      0.999          1      0.995      0.694\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      25/50      2.55G      1.233     0.6065      1.075         49        640: 100%|██████████| 938/938 [02:06<00:00,  7.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:15<00:00,  4.14it/s]\n",
      "                   all       2020       8080      0.999          1      0.995      0.696\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      26/50      2.55G      1.234     0.5968      1.074         46        640: 100%|██████████| 938/938 [02:06<00:00,  7.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:15<00:00,  4.12it/s]\n",
      "                   all       2020       8080      0.999          1      0.995      0.703\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      27/50      2.55G       1.23     0.5936      1.072         38        640: 100%|██████████| 938/938 [02:05<00:00,  7.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:15<00:00,  4.14it/s]\n",
      "                   all       2020       8080      0.999          1      0.995      0.705\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      28/50      2.55G      1.228     0.5886       1.07         58        640: 100%|██████████| 938/938 [02:05<00:00,  7.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:15<00:00,  4.18it/s]\n",
      "                   all       2020       8080      0.999          1      0.995      0.702\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      29/50      2.55G      1.223     0.5825      1.071         39        640: 100%|██████████| 938/938 [02:05<00:00,  7.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:15<00:00,  4.12it/s]\n",
      "                   all       2020       8080      0.999          1      0.995      0.705\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      30/50      2.55G      1.221     0.5781      1.069         54        640: 100%|██████████| 938/938 [02:06<00:00,  7.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:15<00:00,  4.20it/s]\n",
      "                   all       2020       8080      0.999          1      0.995      0.703\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      31/50      2.55G       1.22      0.574      1.065         56        640: 100%|██████████| 938/938 [02:07<00:00,  7.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:15<00:00,  4.14it/s]\n",
      "                   all       2020       8080      0.999          1      0.995      0.705\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      32/50      2.54G      1.216     0.5704      1.066         36        640: 100%|██████████| 938/938 [02:06<00:00,  7.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:15<00:00,  4.12it/s]\n",
      "                   all       2020       8080      0.999          1      0.995      0.714\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      33/50      2.55G      1.213      0.564      1.064         39        640: 100%|██████████| 938/938 [02:06<00:00,  7.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:15<00:00,  4.16it/s]\n",
      "                   all       2020       8080      0.999          1      0.995      0.714\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      34/50      2.54G      1.206     0.5593      1.063         69        640: 100%|██████████| 938/938 [02:06<00:00,  7.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:16<00:00,  3.90it/s]\n",
      "                   all       2020       8080      0.999          1      0.995      0.721\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      35/50      2.55G      1.203     0.5519       1.06         41        640: 100%|██████████| 938/938 [02:06<00:00,  7.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:16<00:00,  3.98it/s]\n",
      "                   all       2020       8080      0.999          1      0.995      0.725\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      36/50      2.54G      1.203     0.5507      1.058         49        640: 100%|██████████| 938/938 [02:05<00:00,  7.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:16<00:00,  3.96it/s]\n",
      "                   all       2020       8080      0.999          1      0.995      0.722\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      37/50      2.55G        1.2     0.5486      1.059         66        640: 100%|██████████| 938/938 [02:06<00:00,  7.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:16<00:00,  3.95it/s]\n",
      "                   all       2020       8080      0.999          1      0.995       0.73\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      38/50      2.54G      1.197     0.5429      1.056         39        640: 100%|██████████| 938/938 [02:06<00:00,  7.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:16<00:00,  3.99it/s]\n",
      "                   all       2020       8080      0.999          1      0.995      0.727\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      39/50      2.55G      1.194     0.5408      1.054         31        640: 100%|██████████| 938/938 [02:07<00:00,  7.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:16<00:00,  3.91it/s]\n",
      "                   all       2020       8080      0.999          1      0.995       0.73\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      40/50      2.54G      1.192     0.5373      1.056         34        640: 100%|██████████| 938/938 [02:07<00:00,  7.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:16<00:00,  3.94it/s]\n",
      "                   all       2020       8080      0.999          1      0.995      0.737\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      41/50      2.56G      1.167     0.4428      1.108         31        640: 100%|██████████| 938/938 [01:59<00:00,  7.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:16<00:00,  3.83it/s]\n",
      "                   all       2020       8080      0.999          1      0.995      0.741\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      42/50      2.55G      1.161     0.4362        1.1         32        640: 100%|██████████| 938/938 [02:02<00:00,  7.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:16<00:00,  4.00it/s]\n",
      "                   all       2020       8080      0.999          1      0.995      0.746\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      43/50      2.56G      1.157     0.4334      1.104         32        640: 100%|██████████| 938/938 [02:02<00:00,  7.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:16<00:00,  3.95it/s]\n",
      "                   all       2020       8080      0.999          1      0.995       0.75\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      44/50      2.55G      1.153     0.4287      1.101         32        640: 100%|██████████| 938/938 [02:02<00:00,  7.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:15<00:00,  4.01it/s]\n",
      "                   all       2020       8080      0.999          1      0.995      0.753\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      45/50      2.56G      1.146     0.4233      1.097         32        640: 100%|██████████| 938/938 [02:02<00:00,  7.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:16<00:00,  3.94it/s]\n",
      "                   all       2020       8080      0.999          1      0.995      0.759\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      46/50      2.55G      1.147     0.4199      1.098         32        640: 100%|██████████| 938/938 [02:03<00:00,  7.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:16<00:00,  3.93it/s]\n",
      "                   all       2020       8080      0.999          1      0.995      0.766\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      47/50      2.56G       1.14     0.4176      1.097         32        640: 100%|██████████| 938/938 [02:02<00:00,  7.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:16<00:00,  3.93it/s]\n",
      "                   all       2020       8080      0.999          1      0.995      0.771\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      48/50      2.55G      1.136     0.4129      1.093         31        640: 100%|██████████| 938/938 [02:02<00:00,  7.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:15<00:00,  4.01it/s]\n",
      "                   all       2020       8080      0.999          1      0.995      0.772\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      49/50      2.56G      1.132     0.4087      1.092         32        640: 100%|██████████| 938/938 [02:02<00:00,  7.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:16<00:00,  3.97it/s]\n",
      "                   all       2020       8080      0.999          1      0.995      0.776\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      50/50      2.55G       1.13     0.4043       1.09         32        640: 100%|██████████| 938/938 [02:03<00:00,  7.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:19<00:00,  3.31it/s]\n",
      "                   all       2020       8080      0.999          1      0.995      0.778\n",
      "\n",
      "50 epochs completed in 2.024 hours.\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\last.pt, 6.3MB\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\best.pt, 6.3MB\n",
      "\n",
      "Validating runs\\detect\\train\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.159  Python-3.11.0 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3015788 parameters, 0 gradients\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:18<00:00,  3.50it/s]\n",
      "                   all       2020       8080      0.999          1      0.995      0.778\n",
      "                   10C       2020        172      0.999          1      0.995      0.777\n",
      "                   10D       2020        161      0.999          1      0.995      0.787\n",
      "                   10H       2020        148      0.999          1      0.995      0.793\n",
      "                   10S       2020        153      0.999          1      0.995      0.792\n",
      "                    2C       2020        144      0.999          1      0.995      0.795\n",
      "                    2D       2020        165      0.999          1      0.995      0.766\n",
      "                    2H       2020        183      0.999          1      0.995      0.781\n",
      "                    2S       2020        137      0.999          1      0.995      0.786\n",
      "                    3C       2020        176      0.999          1      0.995       0.79\n",
      "                    3D       2020        145          1          1      0.995      0.802\n",
      "                    3H       2020        168      0.999          1      0.995      0.769\n",
      "                    3S       2020        142          1          1      0.995      0.788\n",
      "                    4C       2020        173      0.999          1      0.995      0.772\n",
      "                    4D       2020        119      0.999          1      0.995      0.764\n",
      "                    4H       2020        146      0.999          1      0.995      0.765\n",
      "                    4S       2020        145      0.998          1      0.995      0.769\n",
      "                    5C       2020        177      0.999          1      0.995      0.784\n",
      "                    5D       2020        182      0.999          1      0.995      0.769\n",
      "                    5H       2020        166      0.999          1      0.995      0.778\n",
      "                    5S       2020        157      0.999          1      0.995      0.772\n",
      "                    6C       2020        167      0.999          1      0.995      0.788\n",
      "                    6D       2020        175      0.999          1      0.995      0.768\n",
      "                    6H       2020        113      0.999          1      0.995      0.775\n",
      "                    6S       2020        129      0.999          1      0.995      0.779\n",
      "                    7C       2020        145      0.999          1      0.995      0.803\n",
      "                    7D       2020        167          1          1      0.995      0.756\n",
      "                    7H       2020        160          1          1      0.995      0.789\n",
      "                    7S       2020        148          1          1      0.995      0.794\n",
      "                    8C       2020        152      0.998          1      0.995      0.771\n",
      "                    8D       2020        171      0.999          1      0.995      0.783\n",
      "                    8H       2020        166      0.999          1      0.995      0.779\n",
      "                    8S       2020        152      0.999          1      0.995      0.787\n",
      "                    9C       2020        147      0.999          1      0.995      0.786\n",
      "                    9D       2020        140      0.999          1      0.995      0.759\n",
      "                    9H       2020        172      0.999          1      0.995      0.777\n",
      "                    9S       2020        154      0.999          1      0.995      0.775\n",
      "                    AC       2020        181      0.999          1      0.995      0.781\n",
      "                    AD       2020        146      0.999          1      0.995      0.753\n",
      "                    AH       2020        166          1          1      0.995      0.761\n",
      "                    AS       2020        144          1          1      0.995      0.755\n",
      "                    JC       2020        137      0.999          1      0.995      0.782\n",
      "                    JD       2020        145          1          1      0.995      0.766\n",
      "                    JH       2020        151      0.999          1      0.995      0.756\n",
      "                    JS       2020        144          1      0.997      0.995      0.755\n",
      "                    KC       2020        198          1          1      0.995      0.758\n",
      "                    KD       2020        144      0.999          1      0.995      0.786\n",
      "                    KH       2020        160      0.999          1      0.995      0.788\n",
      "                    KS       2020        118      0.999          1      0.995      0.786\n",
      "                    QC       2020        142      0.999          1      0.995      0.801\n",
      "                    QD       2020        174          1          1      0.995      0.775\n",
      "                    QH       2020        152      0.999          1      0.995       0.77\n",
      "                    QS       2020        161      0.999          1      0.995      0.799\n",
      "Speed: 0.3ms preprocess, 1.7ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001B[1mruns\\detect\\train\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "results = training_model.train(data=\"Dataset/data.yaml\", epochs=50, device=0) # IMplement callback"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Aman's Laptop\\Documents\\DNNProjects\\PokerHandDetection\\Dataset\\train\\images\\000056694_jpg.rf.d3044032743b059a02077deb4bbf4cea.jpg: 640x640 1 2D, 2 8Cs, 1 9C, 20.0ms\n",
      "Speed: 10.0ms preprocess, 20.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "results_new = training_model.predict(\"Dataset/train/images/000056694_jpg.rf.d3044032743b059a02077deb4bbf4cea.jpg\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 8D, 1 9D, 21.0ms\n",
      "Speed: 4.0ms preprocess, 21.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"test.jpg\")\n",
    "result = training_model.predict(image)\n",
    "\n",
    "if image is not None:\n",
    "    # Display the image in a window\n",
    "    result_arr = result[0].boxes.data\n",
    "    item_dict = result[0].names\n",
    "    print(len(result_arr))\n",
    "    for result in result_arr:\n",
    "        cv2.rectangle(image, (int(result[0]), int(result[1])), (int(result[2]), int(result[3])), (120, int(result[5])/80 * 255, (1-int(result[5]))/80 * 255), 5)\n",
    "    cv2.imshow('Image', image)\n",
    "\n",
    "    # Wait for a key press and close the window\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Image not found or couldn't be loaded.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "model = YOLO(\"best.pt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# def display_text(text, frame, position_tuple):\n",
    "#     font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#     font_scale = 1\n",
    "#     font_color = (255, 255, 255)  # White color\n",
    "#     font_thickness = 2\n",
    "#     text_position = (position_tuple[0], position_tuple[1]-10) # Coordinates for text position\n",
    "#     cv2.putText(frame, text, text_position, font, font_scale, font_color, font_thickness)\n",
    "def display_text(text, frame, position):\n",
    "    x, y = position\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 0.5\n",
    "    font_color = (255, 255, 255)  # White color\n",
    "    font_thickness = 2\n",
    "    text_size, _ = cv2.getTextSize(text, font, font_scale, font_thickness)\n",
    "    width, height = text_size\n",
    "    cv2.rectangle(frame, (x , y-8 - height), ((x + 10 + width), y), (0, 0, 0), thickness = cv2.FILLED)\n",
    "    cv2.putText(frame , text, (x+6, y -height + 4), font, font_scale, font_color, font_thickness)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 8.8ms\n",
      "Speed: 1.0ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Card 0 set()\n",
      "0\n",
      "High Card 0 set()\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 (no detections), 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 13.1ms\n",
      "Speed: 1.0ms preprocess, 13.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.0ms\n",
      "Speed: 1.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Card 0 set()\n",
      "0\n",
      "High Card 0 set()\n",
      "0\n",
      "High Card 0 set()\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.9ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 9.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Card 0 set()\n",
      "0\n",
      "High Card 0 set()\n",
      "0\n",
      "High Card 0 set()\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.5ms\n",
      "Speed: 2.0ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Card 0 set()\n",
      "0\n",
      "High Card 0 set()\n",
      "0\n",
      "High Card 0 set()\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 (no detections), 13.1ms\n",
      "Speed: 3.0ms preprocess, 13.1ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.7ms\n",
      "Speed: 3.0ms preprocess, 12.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.1ms\n",
      "Speed: 2.0ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Card 0 set()\n",
      "0\n",
      "High Card 0 set()\n",
      "0\n",
      "High Card 0 set()\n",
      "0\n",
      "High Card 0 set()\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 9.0ms\n",
      "Speed: 2.1ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Card 0 set()\n",
      "0\n",
      "High Card 0 set()\n",
      "0\n",
      "High Card 0 set()\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 20.0ms\n",
      "Speed: 2.0ms preprocess, 20.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 9.0ms\n",
      "Speed: 0.9ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Card 0 set()\n",
      "0\n",
      "High Card 0 set()\n",
      "0\n",
      "High Card 0 set()\n",
      "0\n",
      "High Card 0 set()\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 (no detections), 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 11.0ms\n",
      "Speed: 2.1ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.3ms\n",
      "Speed: 2.9ms preprocess, 16.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 11.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Card 0 set()\n",
      "0\n",
      "High Card 0 set()\n",
      "0\n",
      "High Card 0 set()\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.9ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 11.1ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Card 0 set()\n",
      "0\n",
      "High Card 0 set()\n",
      "0\n",
      "High Card 0 set()\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.9ms preprocess, 11.1ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 11.1ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Card 0 set()\n",
      "0\n",
      "High Card 0 set()\n",
      "0\n",
      "High Card 0 set()\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 11.5ms\n",
      "Speed: 2.9ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.1ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Card 0 set()\n",
      "0\n",
      "High Card 0 set()\n",
      "0\n",
      "High Card 0 set()\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 11.1ms\n",
      "Speed: 2.0ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 3H, 12.1ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Card 0 set()\n",
      "0\n",
      "High Card 0 set()\n",
      "0\n",
      "High Card 0 set()\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms preprocess, 12.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 3D, 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 3D, 13.9ms\n",
      "Speed: 4.0ms preprocess, 13.9ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 3D, 11.5ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flush 5 {'H'}\n",
      "5\n",
      "Flush 5 {'D'}\n",
      "5\n",
      "Flush 5 {'D'}\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.9ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 3D, 12.1ms\n",
      "Speed: 2.0ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 3Ds, 11.9ms\n",
      "Speed: 3.0ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 3D, 12.6ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flush 5 {'D'}\n",
      "5\n",
      "Flush 5 {'D'}\n",
      "5\n",
      "Full House 6 {'D'}\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 3Ds, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 3Ds, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flush 5 {'D'}\n",
      "5\n",
      "Full House 6 {'D'}\n",
      "6\n",
      "Full House 6 {'D'}\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 3Ds, 11.7ms\n",
      "Speed: 1.9ms preprocess, 11.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 3Ds, 12.1ms\n",
      "Speed: 2.9ms preprocess, 12.1ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 3Ds, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 3Ds, 12.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full House 6 {'D'}\n",
      "6\n",
      "Full House 6 {'D'}\n",
      "6\n",
      "Full House 6 {'D'}\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 3Ds, 15.5ms\n",
      "Speed: 4.0ms preprocess, 15.5ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 3Ds, 13.6ms\n",
      "Speed: 1.9ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 3D, 13.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full House 6 {'D'}\n",
      "6\n",
      "Full House 6 {'D'}\n",
      "6\n",
      "Full House 6 {'D'}\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.1ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 3Ds, 12.0ms\n",
      "Speed: 1.9ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 3D, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 3Ds, 13.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flush 5 {'D'}\n",
      "5\n",
      "Full House 6 {'D'}\n",
      "6\n",
      "Flush 5 {'D'}\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.1ms preprocess, 13.0ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 3D, 13.0ms\n",
      "Speed: 2.1ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 3Ds, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 13.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full House 6 {'D'}\n",
      "6\n",
      "Flush 5 {'D'}\n",
      "5\n",
      "Full House 6 {'D'}\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.9ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 3D, 12.5ms\n",
      "Speed: 1.9ms preprocess, 12.5ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Card 0 set()\n",
      "0\n",
      "Flush 5 {'D'}\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from HandClassification import detect_hand\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "FPS = 45\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    start_time = time.time()\n",
    "    if not ret:\n",
    "        print(\"Error reading frame\")\n",
    "        break\n",
    "    try:\n",
    "        results = model.predict(frame)\n",
    "        result_arr = results[0].boxes.data\n",
    "        item_dict = results[0].names\n",
    "        for result in result_arr:\n",
    "            int_res = [int(x) for x in result]\n",
    "            x1, y1, x2, y2, conf, label = int_res\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2),  (120, label/60 * 255, (1-label)/60 * 255), 5)\n",
    "            display_text(item_dict[label], frame, (x1-10, y1-10))\n",
    "        hand_des = [item_dict[int(result[5])] for result in result_arr]\n",
    "        print(detect_hand(hand_des))\n",
    "        if len(hand_des)  == 5:\n",
    "            display_text(detect_hand(hand_des), frame, (100, 20))\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred while making prediction\", e)\n",
    "    cv2.imshow(\"Live Camera Feed\", frame)\n",
    "    elapsed_time = time.time()-start_time\n",
    "    overflow_time = max(0, 1/(FPS - elapsed_time))\n",
    "    if cv2.waitKey(int(overflow_time*1000))& 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
