{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21203\n"
     ]
    }
   ],
   "source": [
    "train_size = os.listdir(\"Dataset/train/images\")\n",
    "print(len(train_size))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "training_model = YOLO(\"yolov8n.yaml\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21201\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "train_images = os.listdir(\"Dataset/train/images\")\n",
    "train_labels = os.listdir(\"Dataset/train/labels\")\n",
    "REDUCED_SIZE = 8000\n",
    "\n",
    "print(len(os.listdir(\"Dataset/train/images\")))\n",
    "for image, label in zip(train_images[REDUCED_SIZE:], train_labels[REDUCED_SIZE:]):\n",
    "    os.remove(os.path.join(\"Dataset/train/labels\", label))\n",
    "    os.remove(os.path.join(\"Dataset/train/images\", image))\n",
    "# print(os.listdir(\"Dataset/train/labels\"))\n",
    "print(len(os.listdir(\"Dataset/train/labels\")))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'Dataset/train/images'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlistdir\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mDataset/train/images\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m))\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] The system cannot find the path specified: 'Dataset/train/images'"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.171 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.159  Python-3.11.0 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0mtask=detect, mode=train, model=yolov8n.yaml, data=Dataset/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train4\n",
      "Overriding model.yaml nc=80 with nc=52\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    761452  ultralytics.nn.modules.head.Detect           [52, [64, 128, 256]]          \n",
      "YOLOv8n summary: 225 layers, 3020988 parameters, 3020972 gradients\n",
      "\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs\\detect\\train4', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed \n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\Aman's Laptop\\Documents\\DNNProjects\\PokerHandDetection\\Dataset\\train\\labels... 8000 images, 0 backgrounds, 0 corrupt: 100%|██████████| 8000/8000 [00:02<00:00, 2803.30it/s]\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mNew cache created: C:\\Users\\Aman's Laptop\\Documents\\DNNProjects\\PokerHandDetection\\Dataset\\train\\labels.cache\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\Aman's Laptop\\Documents\\DNNProjects\\PokerHandDetection\\Dataset\\valid\\labels.cache... 2020 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2020/2020 [00:00<?, ?it/s]\n",
      "Plotting labels to runs\\detect\\train4\\labels.jpg... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000179, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001B[1mruns\\detect\\train4\u001B[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      2.27G      4.531       6.84      3.702         69        640: 100%|██████████| 500/500 [01:12<00:00,  6.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:15<00:00,  4.24it/s]\n",
      "                   all       2020       8080    0.00276      0.195     0.0024   0.000564\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       2.3G      2.955      4.893      2.401        102        640: 100%|██████████| 500/500 [01:06<00:00,  7.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:16<00:00,  3.90it/s]\n",
      "                   all       2020       8080    0.00938      0.698     0.0149    0.00455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       2.3G      2.437      4.093      1.935        106        640: 100%|██████████| 500/500 [01:07<00:00,  7.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:16<00:00,  3.79it/s]\n",
      "                   all       2020       8080     0.0117      0.845     0.0246    0.00997\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       2.3G      2.177      3.708      1.722        116        640: 100%|██████████| 500/500 [01:07<00:00,  7.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:17<00:00,  3.71it/s]\n",
      "                   all       2020       8080     0.0371      0.362     0.0401     0.0191\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       2.3G      2.009      3.468      1.599         86        640: 100%|██████████| 500/500 [01:08<00:00,  7.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:18<00:00,  3.47it/s]\n",
      "                   all       2020       8080     0.0432      0.462     0.0486     0.0267\n",
      "\n",
      "5 epochs completed in 0.120 hours.\n",
      "Optimizer stripped from runs\\detect\\train4\\weights\\last.pt, 6.3MB\n",
      "Optimizer stripped from runs\\detect\\train4\\weights\\best.pt, 6.3MB\n",
      "\n",
      "Validating runs\\detect\\train4\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.159  Python-3.11.0 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3015788 parameters, 0 gradients\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 64/64 [00:17<00:00,  3.67it/s]\n",
      "                   all       2020       8080     0.0432      0.461     0.0486     0.0267\n",
      "                   10C       2020        172     0.0458      0.424     0.0494     0.0264\n",
      "                   10D       2020        161     0.0533      0.317     0.0522     0.0302\n",
      "                   10H       2020        148     0.0491        0.5     0.0496     0.0297\n",
      "                   10S       2020        153     0.0559      0.222     0.0532     0.0289\n",
      "                    2C       2020        144     0.0484      0.722     0.0562     0.0328\n",
      "                    2D       2020        165      0.063      0.612     0.0938     0.0524\n",
      "                    2H       2020        183     0.0606      0.388     0.0586     0.0329\n",
      "                    2S       2020        137     0.0483      0.467     0.0474     0.0269\n",
      "                    3C       2020        176     0.0501      0.597     0.0606     0.0349\n",
      "                    3D       2020        145     0.0392      0.579     0.0386     0.0238\n",
      "                    3H       2020        168     0.0474      0.571     0.0564     0.0312\n",
      "                    3S       2020        142      0.038      0.535     0.0455     0.0259\n",
      "                    4C       2020        173     0.0381      0.382     0.0366     0.0178\n",
      "                    4D       2020        119     0.0285      0.202     0.0278     0.0153\n",
      "                    4H       2020        146     0.0374      0.623     0.0489     0.0292\n",
      "                    4S       2020        145      0.037      0.441     0.0386     0.0201\n",
      "                    5C       2020        177     0.0384      0.299     0.0401     0.0214\n",
      "                    5D       2020        182     0.0412      0.593     0.0416     0.0232\n",
      "                    5H       2020        166     0.0578      0.199     0.0513     0.0304\n",
      "                    5S       2020        157     0.0416       0.72      0.045     0.0237\n",
      "                    6C       2020        167     0.0496      0.647     0.0533     0.0287\n",
      "                    6D       2020        175     0.0414      0.114     0.0419      0.025\n",
      "                    6H       2020        113     0.0291      0.735     0.0353     0.0204\n",
      "                    6S       2020        129     0.0363      0.628     0.0433      0.021\n",
      "                    7C       2020        145     0.0165     0.0207     0.0192     0.0104\n",
      "                    7D       2020        167     0.0445      0.144     0.0356     0.0181\n",
      "                    7H       2020        160     0.0337      0.263     0.0328     0.0183\n",
      "                    7S       2020        148     0.0117      0.078     0.0189     0.0101\n",
      "                    8C       2020        152     0.0443      0.441     0.0448      0.024\n",
      "                    8D       2020        171     0.0406      0.632     0.0464     0.0267\n",
      "                    8H       2020        166     0.0492      0.777     0.0665     0.0392\n",
      "                    8S       2020        152     0.0435      0.507      0.051     0.0252\n",
      "                    9C       2020        147     0.0436      0.245     0.0416     0.0235\n",
      "                    9D       2020        140     0.0331      0.436     0.0344     0.0192\n",
      "                    9H       2020        172      0.053      0.715     0.0572     0.0342\n",
      "                    9S       2020        154     0.0337      0.351     0.0352     0.0191\n",
      "                    AC       2020        181     0.0542      0.702      0.117     0.0664\n",
      "                    AD       2020        146     0.0579      0.733     0.0859       0.05\n",
      "                    AH       2020        166     0.0524      0.657     0.0581     0.0345\n",
      "                    AS       2020        144     0.0554        0.5     0.0575     0.0331\n",
      "                    JC       2020        137     0.0321      0.445     0.0346     0.0169\n",
      "                    JD       2020        145     0.0323     0.0621     0.0221     0.0118\n",
      "                    JH       2020        151      0.036      0.411     0.0353     0.0197\n",
      "                    JS       2020        144     0.0498      0.528     0.0474     0.0213\n",
      "                    KC       2020        198     0.0551      0.783      0.103     0.0509\n",
      "                    KD       2020        144     0.0394      0.556     0.0598     0.0345\n",
      "                    KH       2020        160     0.0614      0.369     0.0573     0.0337\n",
      "                    KS       2020        118     0.0353       0.39     0.0343      0.018\n",
      "                    QC       2020        142      0.033      0.401     0.0311     0.0153\n",
      "                    QD       2020        174     0.0326      0.149     0.0336     0.0168\n",
      "                    QH       2020        152      0.049      0.783     0.0603     0.0281\n",
      "                    QS       2020        161     0.0466      0.385     0.0416     0.0186\n",
      "Speed: 0.3ms preprocess, 1.7ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001B[1mruns\\detect\\train4\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "results = training_model.train(data=\"Dataset/data.yaml\", epochs=5, device=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Aman's Laptop\\Documents\\DNNProjects\\PokerHandDetection\\Dataset\\train\\images\\000056694_jpg.rf.d3044032743b059a02077deb4bbf4cea.jpg: 640x640 (no detections), 31.7ms\n",
      "Speed: 0.0ms preprocess, 31.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "results_new = training_model.predict(\"Dataset/train/images/000056694_jpg.rf.d3044032743b059a02077deb4bbf4cea.jpg\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"runs/detect/train4/weights/best.pt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 33.4ms\n",
      "Speed: 7.7ms preprocess, 33.4ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"Dataset/train/images/000056694_jpg.rf.d3044032743b059a02077deb4bbf4cea.jpg\")\n",
    "result = model.predict(image)\n",
    "\n",
    "if image is not None:\n",
    "    # Display the image in a window\n",
    "    result_arr = result[0].boxes.data\n",
    "    item_dict = result[0].names\n",
    "    print(len(result_arr))\n",
    "    for result in result_arr:\n",
    "        cv2.rectangle(image, (int(result[0]), int(result[1])), (int(result[2]), int(result[3])), (120, int(result[5])/80 * 255, (1-int(result[5]))/80 * 255), 5)\n",
    "    cv2.imshow('Image', image)\n",
    "\n",
    "    # Wait for a key press and close the window\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Image not found or couldn't be loaded.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
