{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "topics_init = [x for x in os.listdir(\"./bbc-fulltext/bbc\") if x != \"README.TXT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "0    Ad sales boost Time Warner profit\n1     Dollar gains on Greenspan speech\n2    Yukos unit buyer faces loan claim\n3    High fuel prices hit BA's profits\n4    Pernod takeover talk lifts Domecq\nName: heading, dtype: object"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_list = {\"heading\":[], \"topic\":[]}\n",
    "\n",
    "for x in topics_init:\n",
    "    for article_title in os.listdir(os.path.join(\"./bbc-fulltext/bbc\", x)):\n",
    "        with open(os.path.join(\"./bbc-fulltext/bbc\", x, article_title), \"r\") as f:\n",
    "            heading = f.readline()\n",
    "            article_list[\"heading\"].append(heading.split(\"\\n\")[0])\n",
    "            article_list[\"topic\"].append(x)\n",
    "article_df = pd.DataFrame(article_list)\n",
    "article_df[\"heading\"].head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ad sales boost Time Warner profit\n"
     ]
    }
   ],
   "source": [
    "from keras.src.utils import pad_sequences\n",
    "from keras.src.preprocessing.text import Tokenizer\n",
    "\n",
    "headings_arr = article_df[\"heading\"].values\n",
    "heading_tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "heading_tokenizer.fit_on_texts(headings_arr)\n",
    "\n",
    "sequenced_headings = heading_tokenizer.texts_to_sequences(headings_arr)\n",
    "padded_heading = pad_sequences(sequenced_headings, padding=\"post\", truncating=\"post\", maxlen = 10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 0, 0, 0])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "topic_encoder = LabelEncoder()\n",
    "ys = topic_encoder.fit_transform(article_df[\"topic\"].values)\n",
    "ys[:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_heading, ys, train_size=0.8, random_state=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "from keras.src.layers import Embedding, Bidirectional, Dropout, LSTM, Conv1D, GlobalAveragePooling1D, Dense\n",
    "from keras import Sequential\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(len(heading_tokenizer.word_index)+1, 32, input_length = 10),\n",
    "    Dropout(0.2),\n",
    "    Conv1D(64, 4, activation=\"relu\"),\n",
    "    # Bidirectional(LSTM(32)),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(5, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "56/56 [==============================] - 2s 8ms/step - loss: 1.6010 - accuracy: 0.2449 - val_loss: 1.5863 - val_accuracy: 0.2360\n",
      "Epoch 2/20\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.5024 - accuracy: 0.3472 - val_loss: 1.4095 - val_accuracy: 0.4045\n",
      "Epoch 3/20\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0754 - accuracy: 0.5556 - val_loss: 1.1409 - val_accuracy: 0.5079\n",
      "Epoch 4/20\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.6326 - accuracy: 0.8157 - val_loss: 0.9455 - val_accuracy: 0.6764\n",
      "Epoch 5/20\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2935 - accuracy: 0.9472 - val_loss: 0.7997 - val_accuracy: 0.7236\n",
      "Epoch 6/20\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.1165 - accuracy: 0.9837 - val_loss: 0.7660 - val_accuracy: 0.7438\n",
      "Epoch 7/20\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0489 - accuracy: 0.9972 - val_loss: 0.7588 - val_accuracy: 0.7506\n",
      "Epoch 8/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.7851 - val_accuracy: 0.7506\n",
      "Epoch 9/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0143 - accuracy: 0.9994 - val_loss: 0.8038 - val_accuracy: 0.7461\n",
      "Epoch 10/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.8127 - val_accuracy: 0.7393\n",
      "Epoch 11/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.8401 - val_accuracy: 0.7461\n",
      "Epoch 12/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.8631 - val_accuracy: 0.7438\n",
      "Epoch 13/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.8655 - val_accuracy: 0.7438\n",
      "Epoch 14/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8693 - val_accuracy: 0.7416\n",
      "Epoch 15/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8890 - val_accuracy: 0.7438\n",
      "Epoch 16/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.9064 - val_accuracy: 0.7438\n",
      "Epoch 17/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9092 - val_accuracy: 0.7416\n",
      "Epoch 18/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9200 - val_accuracy: 0.7483\n",
      "Epoch 19/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9227 - val_accuracy: 0.7461\n",
      "Epoch 20/20\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9406 - val_accuracy: 0.7438\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x1d37580ef90>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=20, validation_data=(x_test, y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[284   1   1   0   0   0   0   0   0   0]]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "['sport']\n"
     ]
    }
   ],
   "source": [
    "padded_input = pad_sequences(heading_tokenizer.texts_to_sequences([\"\"]), maxlen=10, padding=\"post\", truncating=\"post\")\n",
    "print(padded_input)\n",
    "prediction = model.predict(padded_input)\n",
    "print(topic_encoder.inverse_transform([np.argmax(prediction)]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "# MODEL 2 Based on pretrained GloVe embeddings\n",
    "\n",
    "glove_embeddings = {}\n",
    "with open(\"./bbc-fulltext/glove.twitter.27B.100d.txt\", \"r\",encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefficients = np.asarray(values[1:], dtype='float32')\n",
    "        glove_embeddings[word] = coefficients\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "word_index = heading_tokenizer.word_index\n",
    "embedding_mtx = np.zeros((len(word_index)+1, 100))\n",
    "for word, i in word_index.items():\n",
    "    embedding = glove_embeddings.get(word)\n",
    "    if embedding is not None:\n",
    "        embedding_mtx[i] = embedding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "model_v2 = Sequential([\n",
    "    Embedding(len(heading_tokenizer.word_index)+1, 100, input_length = 10, weights = [embedding_mtx], trainable=False),\n",
    "    Dropout(0.2),\n",
    "    Conv1D(64, 4, activation=\"relu\"),\n",
    "    # Bidirectional(LSTM(32)),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(5, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_v2.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.1645 - accuracy: 0.9534 - val_loss: 0.4538 - val_accuracy: 0.8539\n",
      "Epoch 2/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.1527 - accuracy: 0.9534 - val_loss: 0.4840 - val_accuracy: 0.8494\n",
      "Epoch 3/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.1362 - accuracy: 0.9584 - val_loss: 0.4450 - val_accuracy: 0.8472\n",
      "Epoch 4/20\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.1300 - accuracy: 0.9674 - val_loss: 0.4606 - val_accuracy: 0.8427\n",
      "Epoch 5/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.1247 - accuracy: 0.9674 - val_loss: 0.4540 - val_accuracy: 0.8337\n",
      "Epoch 6/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.1018 - accuracy: 0.9713 - val_loss: 0.4557 - val_accuracy: 0.8517\n",
      "Epoch 7/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.1101 - accuracy: 0.9674 - val_loss: 0.4525 - val_accuracy: 0.8562\n",
      "Epoch 8/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.1024 - accuracy: 0.9719 - val_loss: 0.4530 - val_accuracy: 0.8404\n",
      "Epoch 9/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0944 - accuracy: 0.9730 - val_loss: 0.4831 - val_accuracy: 0.8449\n",
      "Epoch 10/20\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.0917 - accuracy: 0.9736 - val_loss: 0.4918 - val_accuracy: 0.8360\n",
      "Epoch 11/20\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0743 - accuracy: 0.9848 - val_loss: 0.4669 - val_accuracy: 0.8404\n",
      "Epoch 12/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0703 - accuracy: 0.9809 - val_loss: 0.4661 - val_accuracy: 0.8494\n",
      "Epoch 13/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.9803 - val_loss: 0.4831 - val_accuracy: 0.8449\n",
      "Epoch 14/20\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0747 - accuracy: 0.9798 - val_loss: 0.4786 - val_accuracy: 0.8517\n",
      "Epoch 15/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0605 - accuracy: 0.9820 - val_loss: 0.4610 - val_accuracy: 0.8494\n",
      "Epoch 16/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0534 - accuracy: 0.9904 - val_loss: 0.4849 - val_accuracy: 0.8472\n",
      "Epoch 17/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0561 - accuracy: 0.9865 - val_loss: 0.4759 - val_accuracy: 0.8562\n",
      "Epoch 18/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0590 - accuracy: 0.9860 - val_loss: 0.4901 - val_accuracy: 0.8427\n",
      "Epoch 19/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0472 - accuracy: 0.9916 - val_loss: 0.5129 - val_accuracy: 0.8427\n",
      "Epoch 20/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0550 - accuracy: 0.9865 - val_loss: 0.5120 - val_accuracy: 0.8449\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x1d3a48a10d0>"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_v2.fit(x_train, y_train, epochs=20, validation_data=(x_test, y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "[[9.9087042e-01 5.5080331e-05 5.4712343e-04 1.3137650e-07 8.5272351e-03]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'divide' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[144], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m prediction_v2 \u001B[38;5;241m=\u001B[39m model_v2\u001B[38;5;241m.\u001B[39mpredict(padded_input_v2)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(prediction_v2)\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mProbability: \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprediction_v2\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprediction_v2\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m100\u001B[39m \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m1\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(topic_encoder\u001B[38;5;241m.\u001B[39minverse_transform([np\u001B[38;5;241m.\u001B[39margmax(prediction_v2)]))\n",
      "\u001B[1;31mTypeError\u001B[0m: ufunc 'divide' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "padded_input_v2 = pad_sequences(heading_tokenizer.texts_to_sequences([\"UK economy grows by 0.2%, ONS figures show\"]), maxlen=10, padding=\"post\", truncating=\"post\")\n",
    "prediction_v2 = model_v2.predict(padded_input_v2)\n",
    "print(prediction_v2)\n",
    "# print((\"Probability: \", np.exp(np.max(prediction_v2)))/np.sum(np.exp(prediction_v2)) * 100 // 1, \"%\")\n",
    "print(topic_encoder.inverse_transform([np.argmax(prediction_v2)]))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
